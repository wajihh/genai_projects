{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qFqmeYJ2EPCMVktN79gFFPdJmdmAtyld",
      "authorship_tag": "ABX9TyPDqalK6wl043S6FGChcHxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wajihh/genai_projects/blob/main/langchain_rag_qdrant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Development of RAG QA Bot With LangChain, Qdrant, and OpenAI**\n",
        "\n",
        "  *Acknowledgement: https://medium.com/data-science-at-microsoft/how-i-built-a-superhero-facts-rag-qa-bot-using-langchain-qdrant-and-openai-20a04202c6b1*\n",
        "  *By: Deepsha Menghani*"
      ],
      "metadata": {
        "id": "ZkWWFc83wABh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is RAG?**\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) has emerged as a powerful technique in the world of AI for improving the response accuracy of the AI language model. By combining the generative power of these models with the ability to retrieve relevant information from a knowledge base, RAG systems can provide more accurate, contextual, and factual responses."
      ],
      "metadata": {
        "id": "pExifhYJAfly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S_FJZQmd_7gZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set up the envoirnment"
      ],
      "metadata": {
        "id": "xyexQ7hHwPv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_openai langchain_community langchain_qdrant python-dotenv qdrant-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLxanzLCwbfT",
        "outputId": "051e2e4b-60c7-4ff1-ad4c-dbb80004de62",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.8)\n",
            "Requirement already satisfied: langchain_qdrant in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.10/dist-packages (1.12.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.54.4)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.2)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.10.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.2.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.29.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.7.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.0.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Connect with google drive"
      ],
      "metadata": {
        "id": "iDHnsd-kwqMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect with google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "vSIYl2Zx_lB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeecbe5b-ae8b-41eb-d1ab-ce0cbb607e3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Connect with OpenAI\n",
        "Set up an account on the OpenAI Platform and generate a unique API key. Then, I store this API key in my .env file as OPENAI_API to access it.\n",
        "\n",
        "Next, a client that can interact with OpenAI’s language models. This is where the ChatOpenAI class from LangChain comes into play."
      ],
      "metadata": {
        "id": "m20XyUbhB3kB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load OpenAI and Qdrant API keys from .env and .env.qdrant files\n",
        "load_dotenv(\"/content/drive/MyDrive/Colab Notebooks/.env\")  # For OpenAI\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "load_dotenv(\"/content/drive/MyDrive/Colab Notebooks/.env.qdrant\")  # For Qdrant\n",
        "qdrant_url = os.getenv(\"QDRANT_URL\")\n",
        "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
        "\n",
        "# Set OpenAI API key\n",
        "import openai\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# Check if the keys are loaded correctly\n",
        "print(f\"OpenAI API Key Loaded: {openai_api_key is not None}\")\n",
        "print(f\"Qdrant URL Loaded: {qdrant_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Bhis3dE-_j7",
        "outputId": "efb3a479-5343-4d70-c87f-36d3eb158453"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API Key Loaded: True\n",
            "Qdrant URL Loaded: https://a53aab87-4d9d-4775-b259-285e3a5cefb5.europe-west3-0.gcp.cloud.qdrant.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sh9JO-C2wWJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "#llmclient = ChatOpenAI(openai_api_key=openai_api_key)\n",
        "llmclient = ChatOpenAI(openai_api_key=openai_api_key, model_name=\"gpt-3.5-turbo\", temperature=0.2, max_tokens=100)\n"
      ],
      "metadata": {
        "id": "sL7e8HXJ1p3D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selection of Model and Parameters\n",
        "\n",
        "ChatOpenAI() creates an instance of the ChatOpenAI class, which can interact with OpenAI’s chat models.\n",
        "By default, this uses the gpt-3.5-turbo model, which can be updated by adding a model_name parameter, e.g., model_name=\"gpt-4\".\n",
        "Additional parameters include the following:\n",
        "temperature: Controls randomness in outputs, on a scale from 0 to 1. Higher values (e.g., 0.8) make output more random, while lower values (e.g., 0.2) make it more focused and deterministic.\n",
        "max_tokens: The maximum number of tokens to generate in the chat completion.\n",
        "request_timeout: How many seconds to wait for the request to complete before timing out."
      ],
      "metadata": {
        "id": "r1iPUq0IC6mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose Model Parameters as per requirement\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "from langchain_openai import ChatOpenAI\n",
        "# ##Create a loop for user input questions for chatbot\n",
        "# ##Set up the envoirnment\n",
        "!pip install langchain langchain_openai langchain_community langchain_qdrant python-dotenv qdrant-client\n",
        "# ##Connect with google drive\n",
        "\n",
        "# Load OpenAI and Qdrant API keys from .env and .env.qdrant files\n",
        "load_dotenv(\"/content/drive/MyDrive/Colab Notebooks/.env\")  # For OpenAI\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "load_dotenv(\"/content/drive/MyDrive/Colab Notebooks/.env.qdrant\")  # For Qdrant\n",
        "qdrant_url = os.getenv(\"QDRANT_URL\")\n",
        "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
        "\n",
        "# Set OpenAI API key\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# Check if the keys are loaded correctly\n",
        "print(f\"OpenAI API Key Loaded: {openai_api_key is not None}\")\n",
        "print(f\"Qdrant URL Loaded: {qdrant_url}\")\n",
        "\n",
        "llmclient = ChatOpenAI(openai_api_key=openai_api_key, model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ot7uWDNfRImL",
        "outputId": "c8f0661a-952b-4afa-c5be-40d159b7ef21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.8)\n",
            "Requirement already satisfied: langchain_qdrant in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.10/dist-packages (1.12.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.54.4)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.2)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.10.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.2.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.29.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.7.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.0.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "OpenAI API Key Loaded: True\n",
            "Qdrant URL Loaded: https://a53aab87-4d9d-4775-b259-285e3a5cefb5.europe-west3-0.gcp.cloud.qdrant.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Document\n",
        "The key differentiating component of a RAG system is the knowledge base from which information needs to be retrieved. Inthis knowledge base is stored in a text file. Langchain provides multiple types of loaders for different file types. In this case TextLoader is imported.\n",
        "\n",
        "TextLoader(\"name--.txt\") creates an instance of the TextLoader class, specifying the path to the text file.\n",
        "loader.load() loads the content of the file into memory and returns a list of Document objects with attributes page_content and metadata (aka payload).\n",
        "By loading data into this structured format, it is being preparedfor the next steps in the RAG system, such as splitting the text into chunks and creating embeddings."
      ],
      "metadata": {
        "id": "47Ur5aKbDeY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"/content/drive/MyDrive/2024_Advance_AI/Data/superhero_facts.txt\")\n",
        "documents = loader.load()\n",
        "documents = loader.load()\n"
      ],
      "metadata": {
        "id": "eXbQelN71ppn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunk it up\n",
        "Chunking is a technique used in Generative AI to handle large amounts of data by splitting it into smaller, more manageable pieces. Chunking helps with:\n",
        "\n",
        "Efficient processing: Smaller chunks of text are easier and faster to process, especially when creating embeddings.\n",
        "\n",
        "Relevant retrieval: It allows for more precise retrieval of information by fetching specific, relevant chunks rather than entire documents.\n",
        "\n",
        "Context management: It helps in maintaining appropriate context size for the language model.\n",
        "\n",
        "Adjust parameters with CharacterTextSplitter; this class from LangChain splits text based on character count. Parameters of CharacterTextSplitter include:\n",
        "\n",
        "separator = “\\n”: This tells the splitter to try to break chunks at newline characters. It’s useful for preserving the structure of input file, where each fact is separated by a new line.The separator could be changed to split on different characters (e.g., “. ” to split on sentences) depending on the structure of the data.\n",
        "\n",
        "chunk_size = 200: This sets the target size for each chunk to 200 characters. The separator defines that when this limit is reached, find the next \\n or enter key to close out the chunk. Increasing this would create larger chunks, which might preserve more context but could lead to less precise retrieval. In large-scale scenarios this can have a more visible impact.\n",
        "\n",
        "chunk_overlap = 0: This means there’s no overlap between chunks. Each character from the original text appears in exactly one chunk. It can be adjusted based on the specific needs and nature of the data. For instance, if I wanted some text to carry forward from one chunk to the next because the continuity of it is as important as the content itself, then I would enter a higher overlap number."
      ],
      "metadata": {
        "id": "2GVKQ97MFDbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "  separator = \"\\n\",\n",
        "  chunk_size = 200,\n",
        "  chunk_overlap = 10\n",
        ")\n",
        "\n",
        "loader = TextLoader(\"/content/drive/MyDrive/2024_Advance_AI/Data/superhero_facts.txt\")\n",
        "documents = loader.load_and_split(\n",
        "  text_splitter=text_splitter\n",
        ")"
      ],
      "metadata": {
        "id": "q5u7JTC94oCJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the output of chunking part by printing it out:"
      ],
      "metadata": {
        "id": "Jj8vosvYG6b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in documents:\n",
        "  print(doc.page_content)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CYyliU5d44tR",
        "outputId": "7047ae4e-1ed4-473c-a299-632847cc951e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Ant-Man (Hank Pym) discovered subatomic particles known as \"Pym Particles.\"\n",
            "2. Ant-Man created serums that could shrink or grow objects and people.\n",
            "\n",
            "\n",
            "3. Ant-Man developed a cybernetic helmet to communicate with ants.\n",
            "4. Ant-Man battled various villains like Egghead using his size-changing abilities.\n",
            "\n",
            "\n",
            "5. Ant-Man is a founding member of the Avengers alongside Wasp.\n",
            "6. Aquaman's real name is Arthur Curry, also known as Orin.\n",
            "7. Aquaman is the telepathic ruler of Atlantis and the Earth's oceans.\n",
            "\n",
            "\n",
            "8. Aquaman has superhuman strength, speed, and the ability to command sea life.\n",
            "9. Aquaman is a founding member of the Justice League of America.\n",
            "10. Aquaman's most consistent nemesis is Black Manta.\n",
            "\n",
            "\n",
            "11. Bane was born and raised in the Peña Duro prison in Santa Prisca.\n",
            "12. Bane developed extraordinary physical and mental skills while imprisoned.\n",
            "\n",
            "\n",
            "13. Bane became a test subject for a drug called Venom, which enhanced his strength.\n",
            "14. Bane is famous for breaking Batman's back in the \"Knightfall\" storyline.\n",
            "\n",
            "\n",
            "15. Bane's intelligence is as formidable as his physical strength, making him a dangerous foe.\n",
            "16. Batwoman (Helena Wayne) is the daughter of Bruce Wayne and Selina Kyle from an alternate Earth.\n",
            "\n",
            "\n",
            "17. Batwoman was raised to become Batman's eventual successor.\n",
            "18. Batwoman fought alongside her father as Robin on her Earth.\n",
            "\n",
            "\n",
            "19. Batwoman witnessed her father's death while defending against Parademons.\n",
            "20. Batwoman and her friend Supergirl were transported to another universe through a Boom Tube.\n",
            "\n",
            "\n",
            "21. Black Panther (1,000,000 B.C.) discovered a Vibranium meteor and unlocked its secrets.\n",
            "22. Black Panther (1,000,000 B.C.) was part of the Stone Age Avengers.\n",
            "\n",
            "\n",
            "23. Black Panther (1,000,000 B.C.) fought against an out-of-control Celestial called the Fallen.\n",
            "\n",
            "\n",
            "24. Black Panther (1,000,000 B.C.) helped defeat and seal the Fallen in an underground chamber in South Africa.\n",
            "\n",
            "\n",
            "25. Black Panther (1,000,000 B.C.)'s history after defeating the Fallen is largely unknown.\n",
            "26. Buffy Summers became the Slayer at the age of fifteen.\n",
            "\n",
            "\n",
            "27. Buffy was initially trained by her first Watcher, Merrick.\n",
            "28. Buffy defeated the vampire king Lothos in her first major battle.\n",
            "\n",
            "\n",
            "29. Buffy moved to Sunnydale and became friends with Xander Harris and Willow Rosenberg.\n",
            "30. Buffy formed the \"Scooby Gang\" to battle supernatural threats in Sunnydale.\n",
            "\n",
            "\n",
            "31. Captain America 2099 is Roberta Mendez, wife of an Alchemax Operative.\n",
            "32. Captain America 2099 was forcefully subjected to the Super-Soldier Serum.\n",
            "\n",
            "\n",
            "33. Captain America 2099 became the leader of Alchemax's Avengers.\n",
            "34. Captain America 2099 and Roberta Mendez are two different personas of the same woman.\n",
            "\n",
            "\n",
            "35. Captain America 2099 is unaware of her superhero identity when she's Roberta Mendez.\n",
            "36. Captain America (Venomized) is one of only two men to receive the super-soldier formula.\n",
            "\n",
            "\n",
            "37. Captain America (Venomized) was bonded to a symbiote as a government experiment.\n",
            "38. Captain America (Venomized) maintained control over the symbiote due to his strong will.\n",
            "\n",
            "\n",
            "39. Captain America (Venomized) joined Toxin's resistance against other symbiotes.\n",
            "40. Captain America (Venomized) uses a circular shield with extremely sharp edges as his weapon.\n",
            "\n",
            "\n",
            "51. Captain Planet is formed by combining the powers of the five Planeteers' rings.\n",
            "52. Captain Planet's powers represent earth, fire, wind, water, and heart.\n",
            "\n",
            "\n",
            "53. Captain Planet has sky-blue skin, grass-green hair, and a crystal-compound body.\n",
            "54. Captain Planet possesses a wide array of powers, including flight, super strength, and shapeshifting.\n",
            "\n",
            "\n",
            "55. Captain Planet's weakness is pollution, which diminishes his powers.\n",
            "56. Catwoman (Injustice) grew up in the harsh environment of Gotham City.\n",
            "\n",
            "\n",
            "57. Catwoman (Injustice) worked as a dominatrix in the East End before becoming a costumed thief.\n",
            "\n",
            "\n",
            "58. Catwoman (Injustice) was inspired to become a costumed criminal after seeing Batman in his early days.\n",
            "\n",
            "\n",
            "59. Catwoman (Injustice) has a complex relationship with Batman, sometimes as an adversary and sometimes as an ally.\n",
            "\n",
            "\n",
            "60. Catwoman (Injustice) has evolved into more of an antihero, serving as a constant ally to the Bat-Family.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings and vector database setup\n",
        "\n",
        "Embeddings convert text into numerical vectors that capture semantic meaning for more efficient similarity searches. For this projec OpenAI’s embeddings and Qdrant are used as our vector database.\n",
        "\n",
        "These are the steps I followed in the code:\n",
        "\n",
        "1. Creating embeddings: The OpenAIEmbeddings class handles the API calls to OpenAI’s embedding endpoint.\n",
        "\n",
        "2. Setting up Qdrant client: Qdrant is a vector similarity search engine. It is used to store and retrieve the embeddings efficiently. Here QdrantClient is created that stores data locally in an embeddings directory. This local storage approach is great for development and smaller datasets. For production or larger datasets, this might not be feasible, other approaches like cloud offerings or servers shall be required.\n",
        "\n",
        "3. Creating or accessing the collection: Check to see whether the collection already exists. If not, create it with specific vector parameters. Set size=1536 in VectorParams corresponding to the dimensionality of OpenAI’s embeddings. Here cosine similarity is used for vector comparisons, which is effective for measuring the similarity between two vectors regardless of magnitude.\n",
        "\n",
        "4.  Initializing the Qdrant vector store: Initialize the Qdrant vector store with the client, collection name, and embeddings. This step connects LangChain’s Qdrant integration with Qdrant client and OpenAI embeddings. It creates a db object that I use to add documents and perform similarity searches.\n",
        "\n",
        "5.  Adding documents to the vector store: This converts each text chunk into an embedding and stores it in the Qdrant collection."
      ],
      "metadata": {
        "id": "cnhg2XT3HI0E"
      }
    },
    {
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_qdrant import Qdrant\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams\n",
        "\n",
        "# Provide openai_api_key as a keyword argument\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "# Embeddings stored locally in drive folder\n",
        "# client = QdrantClient(path=\"./embeddings\")\n",
        "# Instead of using local Qdrant, connect to your Qdrant server:\n",
        "client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key) # Use qdrant_url and qdrant_api_key from your environment\n",
        "collection_name = \"superhero_embeddings\"\n",
        "if collection_name not in [c.name for c in client.get_collections().collections]:\n",
        "  client.create_collection(\n",
        "  collection_name=collection_name,\n",
        "  vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
        ")\n",
        "\n",
        "db = Qdrant(client=client, collection_name=collection_name, embeddings=embeddings)\n",
        "db.add_documents(documents)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1kbVcb866-D3",
        "outputId": "a23594dc-b700-4569-ca28-b00225e3ccc1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-027a6a001b93>:19: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.1.2 and will be removed in 0.5.0. Use :class:`~QdrantVectorStore` instead.\n",
            "  db = Qdrant(client=client, collection_name=collection_name, embeddings=embeddings)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dda7824b5bb74b4f9f0a57eec147c508',\n",
              " '804087fb82234d9899a2dc366bf42baa',\n",
              " '0adea64c5293427cb52fb70578a99718',\n",
              " '00d28b4bee7f4d069032dec6a3096cff',\n",
              " '8e0ca55b8e014655ac545386de4be788',\n",
              " 'bd02e163f3f84fd08f627e5893ff67cc',\n",
              " '679c13d674ad4b9c9ff55053a1ecd711',\n",
              " '83d546b3548a42a693e515dab4908b96',\n",
              " 'eecfdc6326cd4d74a521ff3090ac102a',\n",
              " 'b8e45d1203324e1391720a709c462f98',\n",
              " '8a08deb1fd344ec4873529aaab80579e',\n",
              " '49d230b7e7414a9eafff27fd96a587da',\n",
              " '0e5a3d6b70234d058d259f6f41a08f9a',\n",
              " '19bac8e0edd6445b8764b581111f7e53',\n",
              " '5c23cb06485745768f1ea2775ecdef17',\n",
              " '44b819d55a8f44b7b822a5489a86b74f',\n",
              " '95179a18ea004f83a742028797e9bb93',\n",
              " '303f85f13c984d3c958c0880b2291ce0',\n",
              " '09cd96859f074331a01457f524c8d443',\n",
              " '973b819df54b4fb497b838ac083262d5',\n",
              " '006156f5e31c49eabf26310352a1e690',\n",
              " '64aa8bf275bd4da68b059018127125dd',\n",
              " '6f5140fc51c646a48c9c487e160101f0',\n",
              " '3751770b5dbf4bbe9fedbffaaf15a045',\n",
              " 'd16faa2ce36e4266b27976f2cbc241b7',\n",
              " '3720ade0fdd4449f92a9c3d693fdb6a4',\n",
              " '369819cf2b51480a9ba0eb5eff8a6822']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create the Retrieval QA Chain\n",
        "The Retrieval QA Chain is where I will bring together the retrieval mechanism through vector store and the language model to create a system that can answer questions based on knowledge base:\n",
        "\n",
        "1.  Setting up the retriever: First, convert the Qdrant vector store into a retriever object. The retriever is responsible for fetching the most relevant documents from the vector store based on a given query. There are additional parameters that you can play around with, such as search_type (e.g., “similarity”, “mmr” for maximum marginal relevance) and search_kwargs (e.g., to specify the number of documents to retrieve).\n",
        "\n",
        "2.  Creating the RetrievalQA Chain: Now use the RetrievalQA class from LangChain and create a chain specifying the language llm, retriever, and chain_type. The chain type specifies how to process the retrieved documents.\n"
      ],
      "metadata": {
        "id": "gxNp7y7qNGmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "  llm=llmclient,\n",
        "  retriever=retriever,\n",
        "  chain_type=\"stuff\"\n",
        ")"
      ],
      "metadata": {
        "id": "vRHJT3LL7X-e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The “stuff” chain type means that all retrieved documents are stuffed into the prompt sent to the language model. While this is suitable for smaller sets of retrieved documents, other chain types (like “map_reduce”, “refine”, or “rerank”) might be more suitable for other scenarios. For instance, “map_reduce” processes each document separately, then combines the results, while “refine” iteratively updates the answer with each document and “rerank” first applies the language model to each retrieved document individually, ranks these processed documents based on their relevance to the question, and then selects the highest-ranked result as the final answer."
      ],
      "metadata": {
        "id": "IhW2uTBCN05W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Update the while loop\n",
        "\n",
        "Update the while loop to invoke the chain and get the results to test them out."
      ],
      "metadata": {
        "id": "7_HiybaCOB22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  humaninput = input(\">> \")\n",
        "  result = chain.invoke(humaninput)\n",
        "  print(result['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GqVmXz0b7iUO",
        "outputId": "1e4178b1-20bf-4dae-8612-8b1acdfde588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> describe ant man in detail\n",
            "Ant-Man is a superhero in the Marvel Universe who has the ability to shrink down to the size of an ant while retaining his full strength. His real name is Hank Pym, a brilliant scientist who developed the Pym Particles that allow him to change size. He also created a cybernetic helmet that enables him to communicate with and control ants. Ant-Man has used his size-changing abilities to battle various villains, such as Egghead, and has been a member of superhero teams like the Avengers\n",
            ">> which super heros are mentioned?\n",
            "The superheroes mentioned in the context are Captain America 2099 and Captain America (Venomized).\n",
            ">> describe their adventures\n",
            "After witnessing her father's death while defending against Parademons, Batwoman teamed up with her friend Supergirl. Together, they were unexpectedly transported to another universe through a Boom Tube. In this new universe, they faced various challenges and enemies while trying to find a way back home. Their adventures involved battling powerful foes, navigating unfamiliar territories, and relying on each other's strengths to overcome obstacles and ultimately find a way to return to their own universe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Next Steps**\n",
        "\n",
        "RAG system using LangChain and Qdrant has been developed that can load documents, store them efficiently in a vector database, and retrieve relevant information to answer user queries. Important aspects:\n",
        "\n",
        "1.  Semantic search: Converting text chunks into embeddings enables semantic search capabilities. This means it can find relevant information based on meaning, and not just keyword matching.\n",
        "\n",
        "2.  Efficiency: Vector databases like Qdrant are optimized for fast similarity searches in high-dimensional spaces, which is crucial for quick retrieval in RAG systems.\n",
        "\n",
        "3.  Scalability: This setup can handle growing amounts of data efficiently, making it suitable for both small- and large-scale applications; however, you may need to play with parameters and storage based on the scale of your scenario.\n",
        "\n",
        "4.  Flexibility: By using LangChain’s abstractions, I can easily switch to different embedding models or vector stores if needed in the future.\n",
        "\n",
        "The power of this approach is truly unlocked in real-world scenarios. The approach followed can be applied to any domain-specific knowledge base, from customer support to educational tools. For instance:\n",
        "\n",
        "In healthcare, it could assist doctors by quickly retrieving relevant medical literature for specific patient cases.\n",
        "\n",
        "In legal firms, it could help lawyers find pertinent case law and precedents for ongoing litigation.\n",
        "\n",
        "In e-commerce, it could enhance product recommendations by understanding nuanced customer queries.\n",
        "\n",
        "In financial services, it could provide personalized investment advice based on vast amounts of market data and individual client profiles.\n",
        "\n",
        "As you continue to explore RAG systems, consider experimenting with different document types, larger datasets, and more complex chunking and retrieval strategies. This notebook can you get started. Happy coding!\n",
        "\n"
      ],
      "metadata": {
        "id": "3JRl6LPQOspu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resources\n",
        "1.  https://github.com/deepshamenghani/langchain_rag_qdrant\n",
        "2.  LangChain RAG guide\n",
        "3.  OpenAI API Cook Book\n",
        "4.  Qdrant Tutorials-Vector Database Documentation\n",
        "5.  Hugging face RAG guide."
      ],
      "metadata": {
        "id": "CFwB0XXwQZAE"
      }
    }
  ]
}